<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="baidu-site-verification" content="93f8r6fzoB" />
<meta name="google-site-verification" content="TRFlJTt2XTd9bCvpogqNRWkuoxwFeOUBf8ouiChVFyQ" />
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/science_256px_1075043_easyicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/science_128px_1075043_easyicon.ico">
  <link rel="mask-icon" href="/images/stars.svg" color="#222">
  <meta name="google-site-verification" content="TRFlJTt2XTd9bCvpogqNRWkuoxwFeOUBf8ouiChVFyQ">
  <meta name="baidu-site-verification" content="93f8r6fzoB">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://shartoo.github.io').hostname,
    root: '/',
    scheme: 'Pisces',
    version: '7.6.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="深度学习基础理论">
<meta property="og:type" content="article">
<meta property="og:title" content="迁移学习实践-Tensorflow分类任务">
<meta property="og:url" content="https://shartoo.github.io/2022/09/15/2018-06-02-transfer-learning-pratice/index.html">
<meta property="og:site_name" content="数据与算法">
<meta property="og:description" content="深度学习基础理论">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://shartoo.github.io/images/blog/transfer_learning_pratice_1.png">
<meta property="og:image" content="https://shartoo.github.io/images/blog/transfer_learning_pratice_2.png">
<meta property="og:image" content="https://shartoo.github.io/images/blog/transfer_learning_pratice_3.png">
<meta property="og:image" content="https://shartoo.github.io/images/blog/transfer_learning_pratice_4.png">
<meta property="og:image" content="https://shartoo.github.io/images/blog/transfer_learning_pratice_5.png">
<meta property="og:image" content="https://shartoo.github.io/images/blog/transfer_learning_pratice_6.png">
<meta property="og:image" content="https://shartoo.github.io/images/blog/transfer_learning_pratice_7.png">
<meta property="og:image" content="https://shartoo.github.io/images/blog/transfer_learning_pratice_8.png">
<meta property="og:image" content="https://shartoo.github.io/images/blog/transfer_learning_pratice_9.png">
<meta property="og:image" content="https://shartoo.github.io/images/blog/transfer_learning_pratice_10.png">
<meta property="og:image" content="https://shartoo.github.io/images/blog/transfer_learning_pratice_11.png">
<meta property="og:image" content="https://shartoo.github.io/images/blog/transfer_learning_pratice_12.png">
<meta property="og:image" content="https://shartoo.github.io/images/blog/transfer_learning_pratice_13.png">
<meta property="article:published_time" content="2022-09-15T08:16:12.754Z">
<meta property="article:modified_time" content="2022-09-15T08:16:12.754Z">
<meta property="article:author" content="shartoo">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://shartoo.github.io/images/blog/transfer_learning_pratice_1.png">

<link rel="canonical" href="https://shartoo.github.io/2022/09/15/2018-06-02-transfer-learning-pratice/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>迁移学习实践-Tensorflow分类任务 | 数据与算法</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">数据与算法</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">重新出发</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://shartoo.github.io/2022/09/15/2018-06-02-transfer-learning-pratice/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/me.jpg">
      <meta itemprop="name" content="shartoo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="数据与算法">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          迁移学习实践-Tensorflow分类任务
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-09-15 16:16:12" itemprop="dateCreated datePublished" datetime="2022-09-15T16:16:12+08:00">2022-09-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
            <div class="post-description">深度学习基础理论</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>摘自 : <a target="_blank" rel="noopener" href="https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a">medium transfer learning</a></p>
<h2 id="1-说明和准备"><a href="#1-说明和准备" class="headerlink" title="1 说明和准备"></a>1 说明和准备</h2><h3 id="1-1-任务问题"><a href="#1-1-任务问题" class="headerlink" title="1.1 任务问题"></a>1.1 任务问题</h3><p>我们要对只有4000张图片(3000张训练，1000张验证)的数据集做图像分类，分为<code>猫</code>和<code>狗</code>两类。图片数据可以从<a target="_blank" rel="noopener" href="https://www.kaggle.com/c/dogs-vs-cats/data">kaggle 猫狗分类挑战</a>上下载到25000张，不过为了演示迁移学习，假定只有4000张图片。</p>
<h3 id="1-2-数据准备"><a href="#1-2-数据准备" class="headerlink" title="1.2 数据准备"></a>1.2 数据准备</h3><p>首先下载全部的数据集，然后筛选出其中的4000张。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">import glob</span><br><span class="line">import numpy as np</span><br><span class="line">import os</span><br><span class="line">import shutil</span><br><span class="line">np.random.seed(42)</span><br><span class="line">files = glob.glob(&#x27;train/*&#x27;)</span><br><span class="line"># 载入全部的猫狗图片</span><br><span class="line">cat_files = [fn for fn in files if &#x27;cat&#x27; in fn]</span><br><span class="line">dog_files = [fn for fn in files if &#x27;dog&#x27; in fn]</span><br><span class="line">print(len(cat_files), len(dog_files))</span><br><span class="line"># (12500, 12500)</span><br><span class="line"></span><br><span class="line"># 筛选出其中的4000张图片</span><br><span class="line">cat_train = np.random.choice(cat_files, size=1500, replace=False)</span><br><span class="line">dog_train = np.random.choice(dog_files, size=1500, replace=False)</span><br><span class="line">cat_files = list(set(cat_files) - set(cat_train))</span><br><span class="line">dog_files = list(set(dog_files) - set(dog_train))</span><br><span class="line"></span><br><span class="line">cat_val = np.random.choice(cat_files, size=500, replace=False)</span><br><span class="line">dog_val = np.random.choice(dog_files, size=500, replace=False)</span><br><span class="line">cat_files = list(set(cat_files) - set(cat_val))</span><br><span class="line">dog_files = list(set(dog_files) - set(dog_val))</span><br><span class="line"></span><br><span class="line">cat_test = np.random.choice(cat_files, size=500, replace=False)</span><br><span class="line">dog_test = np.random.choice(dog_files, size=500, replace=False)</span><br><span class="line"></span><br><span class="line">print(&#x27;Cat datasets:&#x27;, cat_train.shape, cat_val.shape, cat_test.shape)</span><br><span class="line">print(&#x27;Dog datasets:&#x27;, dog_train.shape, dog_val.shape, dog_test.shape)</span><br><span class="line"># Cat datasets: (1500,) (500,) (500,)</span><br><span class="line"># Dog datasets: (1500,) (500,) (500,)</span><br></pre></td></tr></table></figure>
<p>将数据子集单独放到其他文件夹</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">train_dir = &#x27;training_data&#x27;</span><br><span class="line">val_dir = &#x27;validation_data&#x27;</span><br><span class="line">test_dir = &#x27;test_data&#x27;</span><br><span class="line"></span><br><span class="line">train_files = np.concatenate([cat_train, dog_train])</span><br><span class="line">validate_files = np.concatenate([cat_val, dog_val])</span><br><span class="line">test_files = np.concatenate([cat_test, dog_test])</span><br><span class="line"></span><br><span class="line">os.mkdir(train_dir) if not os.path.isdir(train_dir) else None</span><br><span class="line">os.mkdir(val_dir) if not os.path.isdir(val_dir) else None</span><br><span class="line">os.mkdir(test_dir) if not os.path.isdir(test_dir) else None</span><br><span class="line"></span><br><span class="line">for fn in train_files:</span><br><span class="line">    shutil.copy(fn, train_dir)</span><br><span class="line"></span><br><span class="line">for fn in validate_files:</span><br><span class="line">    shutil.copy(fn, val_dir)</span><br><span class="line">    </span><br><span class="line">for fn in test_files:</span><br><span class="line">    shutil.copy(fn, test_dir)</span><br></pre></td></tr></table></figure>

<p>为模型准备数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import glob</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img</span><br><span class="line"></span><br><span class="line">IMG_DIM = (150, 150)</span><br><span class="line"></span><br><span class="line">train_files = glob.glob(&#x27;training_data/*&#x27;)</span><br><span class="line">train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in train_files]</span><br><span class="line">train_imgs = np.array(train_imgs)</span><br><span class="line">train_labels = [fn.split(&#x27;\\&#x27;)[1].split(&#x27;.&#x27;)[0].strip() for fn in train_files]</span><br><span class="line"></span><br><span class="line">validation_files = glob.glob(&#x27;validation_data/*&#x27;)</span><br><span class="line">validation_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in validation_files]</span><br><span class="line">validation_imgs = np.array(validation_imgs)</span><br><span class="line">validation_labels = [fn.split(&#x27;\\&#x27;)[1].split(&#x27;.&#x27;)[0].strip() for fn in validation_files]</span><br><span class="line"></span><br><span class="line">print(&#x27;Train dataset shape:&#x27;, train_imgs.shape, </span><br><span class="line">      &#x27;\tValidation dataset shape:&#x27;, validation_imgs.shape)</span><br><span class="line"># Train dataset shape: (3000, 150, 150, 3)  </span><br><span class="line"># Validation dataset shape: (1000, 150, 150, 3)</span><br></pre></td></tr></table></figure>
<p>现在，我们得到了3000张训练集和1000张验证集，图像长宽为$150\times 150$，接下来，我们要将图片像素矩阵值取值范围缩放到0到1.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">train_imgs_scaled = train_imgs.astype(&#x27;float32&#x27;)</span><br><span class="line">validation_imgs_scaled = validation_imgs.astype(&#x27;float32&#x27;)</span><br><span class="line">train_imgs_scaled /= 255</span><br><span class="line">validation_imgs_scaled /= 255</span><br><span class="line"></span><br><span class="line">print(train_imgs[0].shape)</span><br><span class="line">array_to_img(train_imgs[0])</span><br></pre></td></tr></table></figure>

<p>一些基本参数，同时将字符型的分类类别改为数值型。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">input_shape = (150, 150, 3)</span><br><span class="line"></span><br><span class="line"># encode text category labels</span><br><span class="line">from sklearn.preprocessing import LabelEncoder</span><br><span class="line"></span><br><span class="line">le = LabelEncoder()</span><br><span class="line">le.fit(train_labels)</span><br><span class="line">train_labels_enc = le.transform(train_labels)</span><br><span class="line">validation_labels_enc = le.transform(validation_labels)</span><br><span class="line"></span><br><span class="line">print(train_labels[1495:1505], train_labels_enc[1495:1505])</span><br><span class="line"># [&#x27;cat&#x27;, &#x27;cat&#x27;, &#x27;cat&#x27;, &#x27;cat&#x27;, &#x27;cat&#x27;, &#x27;dog&#x27;, &#x27;dog&#x27;, &#x27;dog&#x27;, &#x27;dog&#x27;, &#x27;dog&#x27;] [0 0 0 0 0 1 1 1 1 1]</span><br></pre></td></tr></table></figure>

<h2 id="2-基准模型"><a href="#2-基准模型" class="headerlink" title="2 基准模型"></a>2 基准模型</h2><p>先手写个基准的CNN模型，如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout</span><br><span class="line">from keras.models import Sequential</span><br><span class="line">from keras import optimizers</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Conv2D(16, kernel_size=(3, 3), activation=&#x27;relu&#x27;, </span><br><span class="line">                 input_shape=input_shape))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(2, 2)))</span><br><span class="line">model.add(Conv2D(64, kernel_size=(3, 3), activation=&#x27;relu&#x27;))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(2, 2)))</span><br><span class="line">model.add(Conv2D(128, kernel_size=(3, 3), activation=&#x27;relu&#x27;))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(2, 2)))</span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(512, activation=&#x27;relu&#x27;))</span><br><span class="line">model.add(Dense(1, activation=&#x27;sigmoid&#x27;))</span><br><span class="line"></span><br><span class="line">model.compile(loss=&#x27;binary_crossentropy&#x27;,</span><br><span class="line">              optimizer=optimizers.RMSprop(),</span><br><span class="line">              metrics=[&#x27;accuracy&#x27;])</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<p>模型架构如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Layer (type) Output Shape Param #   </span><br><span class="line">=================================================================</span><br><span class="line">conv2d_1 (Conv2D) (None, 148, 148, 16) 448       </span><br><span class="line">_________________________________________________________________</span><br><span class="line">max_pooling2d_1 (MaxPooling2 (None, 74, 74, 16) 0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">conv2d_2 (Conv2D) (None, 72, 72, 64) 9280      </span><br><span class="line">_________________________________________________________________</span><br><span class="line">max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64) 0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">conv2d_3 (Conv2D) (None, 34, 34, 128) 73856     </span><br><span class="line">_________________________________________________________________</span><br><span class="line">max_pooling2d_3 (MaxPooling2 (None, 17, 17, 128) 0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">flatten_1 (Flatten) (None, 36992) 0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense) (None, 512) 18940416  </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_2 (Dense) (None, 1) 513       </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 19,024,513</span><br><span class="line">Trainable params: 19,024,513</span><br><span class="line">Non-trainable params: 0</span><br></pre></td></tr></table></figure>

<p>我们设置<code>batch_size=30</code>，总共有3000张图片，也就是一个epoch需要100次迭代。我们训练30个epoch，然后验证模型。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">batch_size = 30</span><br><span class="line">num_classes = 2</span><br><span class="line">epochs = 30</span><br><span class="line">history = model.fit(x=train_imgs_scaled, y=train_labels_enc,</span><br><span class="line">                    validation_data=(validation_imgs_scaled, validation_labels_enc),</span><br><span class="line">                    batch_size=batch_size,</span><br><span class="line">                    epochs=epochs,</span><br><span class="line">                    verbose=1)</span><br></pre></td></tr></table></figure>
<p>训练过程的输出如下:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Train on 3000 samples, validate on 1000 samples</span><br><span class="line">Epoch 1/30</span><br><span class="line">3000/3000 - 10s - loss: 0.7583 - acc: 0.5627 - val_loss: 0.7182 - val_acc: 0.5520</span><br><span class="line">Epoch 2/30</span><br><span class="line">3000/3000 - 8s - loss: 0.6343 - acc: 0.6533 - val_loss: 0.5891 - val_acc: 0.7190</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">Epoch 29/30</span><br><span class="line">3000/3000 - 8s - loss: 0.0314 - acc: 0.9950 - val_loss: 2.7014 - val_acc: 0.7140</span><br><span class="line">Epoch 30/30</span><br><span class="line">3000/3000 - 8s - loss: 0.0147 - acc: 0.9967 - val_loss: 2.4963 - val_acc: 0.7220</span><br></pre></td></tr></table></figure>
<p>训练集都接近100%准确率了，但是验证集准确率还只有72%。模型可能存在过拟合。可以使用如下的代码画出训练和验证过程的loss下降和准确率变化。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))</span><br><span class="line">t = f.suptitle(&#x27;Basic CNN Performance&#x27;, fontsize=12)</span><br><span class="line">f.subplots_adjust(top=0.85, wspace=0.3)</span><br><span class="line"></span><br><span class="line">epoch_list = list(range(1,31))</span><br><span class="line">ax1.plot(epoch_list, history.history[&#x27;acc&#x27;], label=&#x27;Train Accuracy&#x27;)</span><br><span class="line">ax1.plot(epoch_list, history.history[&#x27;val_acc&#x27;], label=&#x27;Validation Accuracy&#x27;)</span><br><span class="line">ax1.set_xticks(np.arange(0, 31, 5))</span><br><span class="line">ax1.set_ylabel(&#x27;Accuracy Value&#x27;)</span><br><span class="line">ax1.set_xlabel(&#x27;Epoch&#x27;)</span><br><span class="line">ax1.set_title(&#x27;Accuracy&#x27;)</span><br><span class="line">l1 = ax1.legend(loc=&quot;best&quot;)</span><br><span class="line"></span><br><span class="line">ax2.plot(epoch_list, history.history[&#x27;loss&#x27;], label=&#x27;Train Loss&#x27;)</span><br><span class="line">ax2.plot(epoch_list, history.history[&#x27;val_loss&#x27;], label=&#x27;Validation Loss&#x27;)</span><br><span class="line">ax2.set_xticks(np.arange(0, 31, 5))</span><br><span class="line">ax2.set_ylabel(&#x27;Loss Value&#x27;)</span><br><span class="line">ax2.set_xlabel(&#x27;Epoch&#x27;)</span><br><span class="line">ax2.set_title(&#x27;Loss&#x27;)</span><br><span class="line">l2 = ax2.legend(loc=&quot;best&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="/images/blog/transfer_learning_pratice_1.png"></p>
<p>上图左可以看到，3个epoch之后就开始过拟合了，训练准确率一直上升，但是验证准确率保持不变了。</p>
<h3 id="2-1-简单的优化模型"><a href="#2-1-简单的优化模型" class="headerlink" title="2.1 简单的优化模型"></a>2.1 简单的优化模型</h3><p>上面的CNN是个基本的架构，接下来我们做一些优化策略，网络架构上加入正则化，使用一定概率的dropout。只修改网络结构部分，其他训练代码不变。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Conv2D(16, kernel_size=(3, 3), activation=&#x27;relu&#x27;, </span><br><span class="line">                 input_shape=input_shape))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(2, 2)))</span><br><span class="line">model.add(Conv2D(64, kernel_size=(3, 3), activation=&#x27;relu&#x27;))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(2, 2)))</span><br><span class="line">model.add(Conv2D(128, kernel_size=(3, 3), activation=&#x27;relu&#x27;))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(2, 2)))</span><br><span class="line">model.add(Conv2D(128, kernel_size=(3, 3), activation=&#x27;relu&#x27;))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(2, 2)))</span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(512, activation=&#x27;relu&#x27;))</span><br><span class="line">model.add(Dropout(0.3))</span><br><span class="line">model.add(Dense(512, activation=&#x27;relu&#x27;))</span><br><span class="line">model.add(Dropout(0.3))</span><br><span class="line">model.add(Dense(1, activation=&#x27;sigmoid&#x27;))</span><br><span class="line"></span><br><span class="line">model.compile(loss=&#x27;binary_crossentropy&#x27;,</span><br><span class="line">              optimizer=optimizers.RMSprop(),</span><br><span class="line">              metrics=[&#x27;accuracy&#x27;])          </span><br><span class="line">history = model.fit(x=train_imgs_scaled, y=train_labels_enc,</span><br><span class="line">                    validation_data=(validation_imgs_scaled, validation_labels_enc),</span><br><span class="line">                    batch_size=batch_size,</span><br><span class="line">                    epochs=epochs,</span><br><span class="line">                    verbose=1)                      </span><br></pre></td></tr></table></figure>
<p>使用上面的画图代码，画出训练曲线。</p>
<p><img src="/images/blog/transfer_learning_pratice_2.png"></p>
<p>有所改善，但是效果不明显。依然是过拟合，究其原因，数据量太少，可以使用部分的数据集增强策略增加数据多样性。</p>
<h3 id="2-2-使用数据增强策略"><a href="#2-2-使用数据增强策略" class="headerlink" title="2.2 使用数据增强策略"></a>2.2 使用数据增强策略</h3><p>keras的<code>ImageDataGenerator</code>自带了一些数据增强方法，如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,</span><br><span class="line">                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, </span><br><span class="line">                                   horizontal_flip=True, fill_mode=&#x27;nearest&#x27;)</span><br><span class="line">val_datagen = ImageDataGenerator(rescale=1./255)</span><br></pre></td></tr></table></figure>
<p>当然，我们还可以使用 <a target="_blank" rel="noopener" href="https://github.com/albu/albumentations">Albumentations</a>来做更多的增强策略。我们先来看看<code>ImageDataGenerator</code>增强之后的图片效果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mg_id = 2595</span><br><span class="line">cat_generator = train_datagen.flow(train_imgs[img_id:img_id+1], train_labels[img_id:img_id+1],</span><br><span class="line">                                   batch_size=1)</span><br><span class="line">cat = [next(cat_generator) for i in range(0,5)]</span><br><span class="line">fig, ax = plt.subplots(1,5, figsize=(16, 6))</span><br><span class="line">print(&#x27;Labels:&#x27;, [item[1][0] for item in cat])</span><br><span class="line">l = [ax[i].imshow(cat[i][0][0]) for i in range(0,5)]</span><br></pre></td></tr></table></figure>

<p><img src="/images/blog/transfer_learning_pratice_3.png"></p>
<p>再次使用上面的基准模型(加了dropout层的)，此次我们将学习率稍微改小点，将默认的<code>1e-3</code>改为<code>1e-4</code>，防止模型过拟合，此时的数据量增多了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model.compile(loss=&#x27;binary_crossentropy&#x27;,</span><br><span class="line">              optimizer=optimizers.RMSprop(lr=1e-4),</span><br><span class="line">              metrics=[&#x27;accuracy&#x27;])        </span><br><span class="line">history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=100,</span><br><span class="line">                              validation_data=val_generator, validation_steps=50, </span><br><span class="line">                              verbose=1)  </span><br></pre></td></tr></table></figure>
<p>打印训练曲线<br><img src="/images/blog/transfer_learning_pratice_4.png"></p>
<p>模型的准确率提升到**82%**，而且已经不再过拟合了。</p>
<h2 id="3-使用其他模型做迁移学习"><a href="#3-使用其他模型做迁移学习" class="headerlink" title="3 使用其他模型做迁移学习"></a>3 使用其他模型做迁移学习</h2><h3 id="3-1-VGG-16模型"><a href="#3-1-VGG-16模型" class="headerlink" title="3.1 VGG-16模型"></a>3.1 VGG-16模型</h3><p>分类模型，我们选用VGG16为例。首先，我们需要理解VGG16的模型架构，如下</p>
<p><img src="/images/blog/transfer_learning_pratice_5.png"></p>
<p>13个$3\times 3$的卷积，5个maxpooling缩减了网络输入尺寸。在两个全连接层之前的输出是4096个神经元，全连接都是1000个神经元(代表了1000个分类)。由于我们要做的是做猫狗分类，最后三层是不需要的。我们更关心前5个blocks(下图)，我们可以将VGG模型看做一个特征抽取器。下图是VGG模型的三种用法</p>
<p><img src="/images/blog/transfer_learning_pratice_6.png"></p>
<ul>
<li>如果我们只是作为特征抽取器，则按照图中中间的示例，冻结所有的blocks(5个)，在训练过程中，这些blocks中的所有参数都不会更新。</li>
<li>如果我们做fine-tuning，可以考虑按照图右冻结前3个blocks，更新后面两个blocks(4和5)的参数（每个训练epoch过程都会）。</li>
</ul>
<h3 id="3-2-将预训练模型作为特征抽取器"><a href="#3-2-将预训练模型作为特征抽取器" class="headerlink" title="3.2 将预训练模型作为特征抽取器"></a>3.2 将预训练模型作为特征抽取器</h3><p>3.1节中最后一张图的中间的架构，冻结所有blocks层的参数的用法。下面是对应的代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">from keras.applications import vgg16</span><br><span class="line">from keras.models import Model</span><br><span class="line">import keras</span><br><span class="line"></span><br><span class="line">vgg = vgg16.VGG16(include_top=False, weights=&#x27;imagenet&#x27;, </span><br><span class="line">                                     input_shape=input_shape)</span><br><span class="line"></span><br><span class="line">output = vgg.layers[-1].output</span><br><span class="line">output = keras.layers.Flatten()(output)</span><br><span class="line">vgg_model = Model(vgg.input, output)</span><br><span class="line"></span><br><span class="line">vgg_model.trainable = False</span><br><span class="line">for layer in vgg_model.layers:</span><br><span class="line">    layer.trainable = False</span><br><span class="line">    </span><br><span class="line">import pandas as pd</span><br><span class="line">pd.set_option(&#x27;max_colwidth&#x27;, -1)</span><br><span class="line">layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]</span><br><span class="line">pd.DataFrame(layers, columns=[&#x27;Layer Type&#x27;, &#x27;Layer Name&#x27;, &#x27;Layer Trainable&#x27;]) </span><br></pre></td></tr></table></figure>
<p><img src="/images/blog/transfer_learning_pratice_7.png"></p>
<p>此处，将VGG模型看做SURF或者HOG特征之类的东西就可以，使用过程不更新参数，直接输入图片，预测得到特征。用法如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bottleneck_feature_example = vgg.predict(train_imgs_scaled[0:1])</span><br><span class="line">print(bottleneck_feature_example.shape)</span><br><span class="line">plt.imshow(bottleneck_feature_example[0][:,:,0])</span><br></pre></td></tr></table></figure>
<p><img src="/images/blog/transfer_learning_pratice_8.png"></p>
<p>从训练数据和验证数据中使用VGG16抽取特征如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def get_bottleneck_features(model, input_imgs):</span><br><span class="line">    features = model.predict(input_imgs, verbose=0)</span><br><span class="line">    return features</span><br><span class="line"></span><br><span class="line">train_features_vgg = get_bottleneck_features(vgg_model, train_imgs_scaled)</span><br><span class="line">validation_features_vgg = get_bottleneck_features(vgg_model, validation_imgs_scaled)</span><br><span class="line">print(&#x27;Train Bottleneck Features:&#x27;, train_features_vgg.shape, </span><br><span class="line">      &#x27;\tValidation Bottleneck Features:&#x27;, validation_features_vgg.shape)</span><br></pre></td></tr></table></figure>
<p>输出如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Train Bottleneck Features: (3000, 8192)  </span><br><span class="line">Validation Bottleneck Features: (1000, 8192)</span><br></pre></td></tr></table></figure>
<p>接下来，我们可以以VGG作为特征抽取器重新构建一个训练模型。其实，在抽取特征之后直接接一个SVM或者KNN分类器也是一样的。下面以keras代码，重新构建CNN模型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer</span><br><span class="line">from keras.models import Sequential</span><br><span class="line">from keras import optimizers</span><br><span class="line"># 此时的vgg_model 已经设置了trainable=False</span><br><span class="line">input_shape = vgg_model.output_shape[1]</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(InputLayer(input_shape=(input_shape,)))</span><br><span class="line">model.add(Dense(512, activation=&#x27;relu&#x27;, input_dim=input_shape))</span><br><span class="line">model.add(Dropout(0.3))</span><br><span class="line">model.add(Dense(512, activation=&#x27;relu&#x27;))</span><br><span class="line">model.add(Dropout(0.3))</span><br><span class="line">model.add(Dense(1, activation=&#x27;sigmoid&#x27;))</span><br><span class="line"></span><br><span class="line">model.compile(loss=&#x27;binary_crossentropy&#x27;,</span><br><span class="line">              optimizer=optimizers.RMSprop(lr=1e-4),</span><br><span class="line">              metrics=[&#x27;accuracy&#x27;])</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<p>网络结构如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type) Output Shape Param #   </span><br><span class="line">=================================================================</span><br><span class="line">input_2 (InputLayer) (None, 8192) 0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense) (None, 512) 4194816   </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dropout_1 (Dropout) (None, 512) 0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_2 (Dense) (None, 512) 262656    </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dropout_2 (Dropout) (None, 512) 0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_3 (Dense) (None, 1) 513       </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 4,457,985</span><br><span class="line">Trainable params: 4,457,985</span><br><span class="line">Non-trainable params: 0</span><br></pre></td></tr></table></figure>
<p><strong>注意，此时的训练代码中输入数据不再是图片，而是VGG抽取的特征了</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit(x=train_features_vgg, y=train_labels_enc,</span><br><span class="line">                    validation_data=(validation_features_vgg, validation_labels_enc),</span><br><span class="line">                    batch_size=batch_size,</span><br><span class="line">                    epochs=epochs,</span><br><span class="line">                    verbose=1)</span><br></pre></td></tr></table></figure>

<p><img src="/images/blog/transfer_learning_pratice_9.png"></p>
<p>验证准确率提升到**88%**，虽然看起来依然过拟合了。</p>
<h3 id="3-3-使用数据增强-VGG作为特征抽取器"><a href="#3-3-使用数据增强-VGG作为特征抽取器" class="headerlink" title="3.3 使用数据增强+VGG作为特征抽取器"></a>3.3 使用数据增强+VGG作为特征抽取器</h3><p>由于我们使用data generator，此处不再用VGG作为特征抽取器.此部分与上面的区别在于，上面的VGG模型不是网络的一部分，属于数据处理部分，用vgg将处理图片(特征抽取)之后的数据传入了新的小网络。而当前是将VGG作为网络的一部分，与新的网络层，构建了一个新模型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,</span><br><span class="line">                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, </span><br><span class="line">                                   horizontal_flip=True, fill_mode=&#x27;nearest&#x27;)</span><br><span class="line"></span><br><span class="line">val_datagen = ImageDataGenerator(rescale=1./255)</span><br><span class="line">train_generator = train_datagen.flow(train_imgs, train_labels_enc, batch_size=30)</span><br><span class="line">val_generator = val_datagen.flow(validation_imgs, validation_labels_enc, batch_size=20)</span><br></pre></td></tr></table></figure>
<p>网络构建部分</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">from keras.applications import vgg16</span><br><span class="line">from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer</span><br><span class="line">from keras.models import Sequential</span><br><span class="line">from keras import optimizers</span><br><span class="line">from keras.models import Model</span><br><span class="line">import keras</span><br><span class="line"></span><br><span class="line">vgg = vgg16.VGG16(include_top=False, weights=&#x27;imagenet&#x27;, </span><br><span class="line">                                     input_shape=input_shape)</span><br><span class="line"></span><br><span class="line">output = vgg.layers[-1].output</span><br><span class="line">output = keras.layers.Flatten()(output)</span><br><span class="line">vgg_model = Model(vgg.input, output)</span><br><span class="line"></span><br><span class="line">vgg_model.trainable = False</span><br><span class="line">for layer in vgg_model.layers:</span><br><span class="line">    layer.trainable = False</span><br><span class="line"># 下面是我们新加的网络层，将VGG放在前面</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(vgg_model)</span><br><span class="line">model.add(Dense(512, activation=&#x27;relu&#x27;, input_dim=input_shape))</span><br><span class="line">model.add(Dropout(0.3))</span><br><span class="line">model.add(Dense(512, activation=&#x27;relu&#x27;))</span><br><span class="line">model.add(Dropout(0.3))</span><br><span class="line">model.add(Dense(1, activation=&#x27;sigmoid&#x27;))</span><br><span class="line"># 学习率变小了</span><br><span class="line">model.compile(loss=&#x27;binary_crossentropy&#x27;,</span><br><span class="line">              optimizer=optimizers.RMSprop(lr=2e-5),</span><br><span class="line">              metrics=[&#x27;accuracy&#x27;])</span><br><span class="line">              </span><br><span class="line">history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=100,</span><br><span class="line">                              validation_data=val_generator, validation_steps=50, </span><br><span class="line">                              verbose=1)       </span><br></pre></td></tr></table></figure>
<p>此时的学习曲线，如下</p>
<p><img src="/images/blog/transfer_learning_pratice_10.png"></p>
<p>此时的验证准确率提升到了90%，而且没有过拟合。</p>
<h3 id="3-5-fine-tuning-预训练的VGG模型-数据增强"><a href="#3-5-fine-tuning-预训练的VGG模型-数据增强" class="headerlink" title="3.5 fine-tuning 预训练的VGG模型+数据增强"></a>3.5 fine-tuning 预训练的VGG模型+数据增强</h3><p>此部分，可以参考3.1节部分VGG示意图的最右边那张图，此时vgg模型中某些blocks的参数也在训练过程中得到更新。如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">vgg_model.trainable = True</span><br><span class="line"></span><br><span class="line">set_trainable = False</span><br><span class="line">for layer in vgg_model.layers:</span><br><span class="line">    if layer.name in [&#x27;block5_conv1&#x27;, &#x27;block4_conv1&#x27;]:</span><br><span class="line">        set_trainable = True</span><br><span class="line">    if set_trainable:</span><br><span class="line">        layer.trainable = True</span><br><span class="line">    else:</span><br><span class="line">        layer.trainable = False</span><br><span class="line">        </span><br><span class="line">layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]</span><br><span class="line">pd.DataFrame(layers, columns=[&#x27;Layer Type&#x27;, &#x27;Layer Name&#x27;, &#x27;Layer Trainable&#x27;])   </span><br></pre></td></tr></table></figure>
<p><img src="/images/blog/transfer_learning_pratice_11.png"></p>
<p>可以看到<code>block4</code>和<code>block5</code>已经变成可以训练了。此时再次减小学习率，同时使用了增强了的数据处理</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,</span><br><span class="line">                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, </span><br><span class="line">                                   horizontal_flip=True, fill_mode=&#x27;nearest&#x27;)</span><br><span class="line">val_datagen = ImageDataGenerator(rescale=1./255)</span><br><span class="line">train_generator = train_datagen.flow(train_imgs, train_labels_enc, batch_size=30)</span><br><span class="line">val_generator = val_datagen.flow(validation_imgs, validation_labels_enc, batch_size=20)</span><br><span class="line"></span><br><span class="line">from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer</span><br><span class="line">from keras.models import Sequential</span><br><span class="line">from keras import optimizers</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(vgg_model)</span><br><span class="line">model.add(Dense(512, activation=&#x27;relu&#x27;, input_dim=input_shape))</span><br><span class="line">model.add(Dropout(0.3))</span><br><span class="line">model.add(Dense(512, activation=&#x27;relu&#x27;))</span><br><span class="line">model.add(Dropout(0.3))</span><br><span class="line">model.add(Dense(1, activation=&#x27;sigmoid&#x27;))</span><br><span class="line"></span><br><span class="line">model.compile(loss=&#x27;binary_crossentropy&#x27;,</span><br><span class="line">              optimizer=optimizers.RMSprop(lr=1e-5),</span><br><span class="line">              metrics=[&#x27;accuracy&#x27;])</span><br><span class="line">              </span><br><span class="line">history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=100,</span><br><span class="line">                              validation_data=val_generator, validation_steps=50, </span><br><span class="line">                              verbose=1)              </span><br></pre></td></tr></table></figure>

<p><img src="/images/blog/transfer_learning_pratice_12.png"></p>
<p>可以看到，验证准确率已经提升到了**96%**，与基准模型相比，提升了24%。</p>
<h2 id="4-测试模型"><a href="#4-测试模型" class="headerlink" title="4 测试模型"></a>4 测试模型</h2><p>接下来在测试集上测试上面的5种模型</p>
<ol>
<li>基准CNN模型</li>
<li>使用了数据增强的基准CNN模型</li>
<li>迁移学习：使用VGG16作为特征抽取器【VGG只用在数据处理上】</li>
<li>迁移学习：使用VGG作为模型的一部分，并且使用了数据增强策略</li>
<li>迁移学习：对VGG模型微调，让其<code>block4</code>和<code>block5</code>参数可更新</li>
</ol>
<p>测试代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">IMG_DIM = (150, 150)</span><br><span class="line"></span><br><span class="line">test_files = glob.glob(&#x27;test_data/*&#x27;)</span><br><span class="line">test_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in test_files]</span><br><span class="line">test_imgs = np.array(test_imgs)</span><br><span class="line">test_labels = [fn.split(&#x27;/&#x27;)[1].split(&#x27;.&#x27;)[0].strip() for fn in test_files]</span><br><span class="line"></span><br><span class="line">test_imgs_scaled = test_imgs.astype(&#x27;float32&#x27;)</span><br><span class="line">test_imgs_scaled /= 255</span><br><span class="line">test_labels_enc = class2num_label_transformer(test_labels)</span><br><span class="line"></span><br><span class="line">print(&#x27;Test dataset shape:&#x27;, test_imgs.shape)</span><br><span class="line">print(test_labels[0:5], test_labels_enc[0:5])</span><br></pre></td></tr></table></figure>
<p>测试基准模型的代码如下（其他模型类似）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">predictions = basic_cnn.predict_classes(test_imgs_scaled, verbose=0)</span><br><span class="line">predictions = num2class_label_transformer(predictions)</span><br><span class="line">meu.display_model_performance_metrics(true_labels=test_labels, predicted_labels=predictions, </span><br><span class="line">                                      classes=list(set(test_labels)))</span><br></pre></td></tr></table></figure>

<p><img src="/images/blog/transfer_learning_pratice_13.png"></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/09/15/2018-08-10-TTS_MSD_HMM/" rel="prev" title="语音合成：MSD-HMM多空间概率分布HMM">
      <i class="fa fa-chevron-left"></i> 语音合成：MSD-HMM多空间概率分布HMM
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/09/15/2018-04-02-LHY_GAN/" rel="next" title="李宏毅深度学习-15-生成网络">
      李宏毅深度学习-15-生成网络 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E8%AF%B4%E6%98%8E%E5%92%8C%E5%87%86%E5%A4%87"><span class="nav-number">1.</span> <span class="nav-text">1 说明和准备</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 任务问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 数据准备</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E5%9F%BA%E5%87%86%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.</span> <span class="nav-text">2 基准模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-%E7%AE%80%E5%8D%95%E7%9A%84%E4%BC%98%E5%8C%96%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 简单的优化模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-%E4%BD%BF%E7%94%A8%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E7%AD%96%E7%95%A5"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 使用数据增强策略</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E4%BD%BF%E7%94%A8%E5%85%B6%E4%BB%96%E6%A8%A1%E5%9E%8B%E5%81%9A%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0"><span class="nav-number">3.</span> <span class="nav-text">3 使用其他模型做迁移学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-VGG-16%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 VGG-16模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-%E5%B0%86%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BD%9C%E4%B8%BA%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96%E5%99%A8"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 将预训练模型作为特征抽取器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-%E4%BD%BF%E7%94%A8%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA-VGG%E4%BD%9C%E4%B8%BA%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96%E5%99%A8"><span class="nav-number">3.3.</span> <span class="nav-text">3.3 使用数据增强+VGG作为特征抽取器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-5-fine-tuning-%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84VGG%E6%A8%A1%E5%9E%8B-%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="nav-number">3.4.</span> <span class="nav-text">3.5 fine-tuning 预训练的VGG模型+数据增强</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-%E6%B5%8B%E8%AF%95%E6%A8%A1%E5%9E%8B"><span class="nav-number">4.</span> <span class="nav-text">4 测试模型</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="shartoo"
      src="/images/me.jpg">
  <p class="site-author-name" itemprop="name">shartoo</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">102</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">shartoo</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v6.3.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.6.0
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/three-waves.min.js"></script>


  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>




  
<script src="/js/local-search.js"></script>













  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: 'c656cd038e01f710e260',
      clientSecret: 'e6de2ccaaf0f7069292125b8f50e27f25b95810d',
      repo: 'shartoo.github.io',
      owner: 'shartoo',
      admin: ['shartoo'],
      id: '04e4bae59dad0d0166809e94ad1cacb2',
        language: '',
      distractionFreeMode: 'true'
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

  <!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>
</body>
</html>
