<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="baidu-site-verification" content="93f8r6fzoB" />
<meta name="google-site-verification" content="TRFlJTt2XTd9bCvpogqNRWkuoxwFeOUBf8ouiChVFyQ" />
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/science_256px_1075043_easyicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/science_128px_1075043_easyicon.ico">
  <link rel="mask-icon" href="/images/stars.svg" color="#222">
  <meta name="google-site-verification" content="TRFlJTt2XTd9bCvpogqNRWkuoxwFeOUBf8ouiChVFyQ">
  <meta name="baidu-site-verification" content="93f8r6fzoB">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://shartoo.github.io').hostname,
    root: '/',
    scheme: 'Pisces',
    version: '7.6.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="深度学习">
<meta property="og:type" content="article">
<meta property="og:title" content="谷歌TensorFlow基本概念">
<meta property="og:url" content="https://shartoo.github.io/2022/09/15/2016-06-13-GoogleTensorFlowBasicConcept/index.html">
<meta property="og:site_name" content="数据与算法">
<meta property="og:description" content="深度学习">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://shartoo.github.io/images/blog/tensorflow_basicconcept.png">
<meta property="article:published_time" content="2022-09-15T08:16:12.750Z">
<meta property="article:modified_time" content="2022-09-15T08:16:12.750Z">
<meta property="article:author" content="shartoo">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://shartoo.github.io/images/blog/tensorflow_basicconcept.png">

<link rel="canonical" href="https://shartoo.github.io/2022/09/15/2016-06-13-GoogleTensorFlowBasicConcept/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>谷歌TensorFlow基本概念 | 数据与算法</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">数据与算法</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">重新出发</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://shartoo.github.io/2022/09/15/2016-06-13-GoogleTensorFlowBasicConcept/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/me.jpg">
      <meta itemprop="name" content="shartoo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="数据与算法">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          谷歌TensorFlow基本概念
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-09-15 16:16:12" itemprop="dateCreated datePublished" datetime="2022-09-15T16:16:12+08:00">2022-09-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
            <div class="post-description">深度学习</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="start-up"><a href="#start-up" class="headerlink" title="start up"></a>start up</h1><h2 id="1-1-谷歌深度学习工具历史"><a href="#1-1-谷歌深度学习工具历史" class="headerlink" title="1.1 谷歌深度学习工具历史:"></a>1.1 谷歌深度学习工具历史:</h2><ol>
<li>第一代：<strong>DistBelief</strong> 由 Dean于2011年发起，主要产品有：<ul>
<li>Inception (图像识别领域)</li>
<li>谷歌Search</li>
<li>谷歌翻译</li>
<li>谷歌照片</li>
</ul>
</li>
<li>第二代：<strong>TensorFlow</strong> 由Dean于2015年11月发起，大部分DistBelief都转向了TensorFlow</li>
</ol>
<h2 id="1-2-产品特性"><a href="#1-2-产品特性" class="headerlink" title="1.2 产品特性"></a>1.2 产品特性</h2><table>
<thead>
<tr>
<th>概念</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>编程模型</td>
<td>类数据流的模型</td>
</tr>
<tr>
<td>语言</td>
<td>Python C++</td>
</tr>
<tr>
<td>部署</td>
<td>code once,run ererywhere</td>
</tr>
<tr>
<td>计算资源</td>
<td>cpu,gpu</td>
</tr>
<tr>
<td>分布式处理</td>
<td>本地实现，分布式实现</td>
</tr>
<tr>
<td>数学表达式</td>
<td>数学图表达式，自动分化</td>
</tr>
<tr>
<td>优化</td>
<td>自动消除，kernel 优化，通信优化，支持模式，数据并行</td>
</tr>
</tbody></table>
<h2 id="1-3-计算图"><a href="#1-3-计算图" class="headerlink" title="1.3 计算图"></a>1.3 计算图</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">b = tf.Variable(tf.zeros([100]))                   # 100维的向量，都初始化为0</span><br><span class="line">w = tf.Variable(tf.random_uniform([784,100],-1,1)) # 784x100的矩阵</span><br><span class="line">x = tf.placeholder(name=&quot;x&quot;)                       # 输入的占位符placeholder</span><br><span class="line">relu = tf.nn.relu(tf.matmul(w,x)+b)                # Relu(Wx+b)</span><br><span class="line">C =[...]                                           # 使用relu的一个函数计算代价</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>对应的计算图如下:<br><img src="/images/blog/tensorflow_basicconcept.png" alt="计算图"></p>
<h2 id="1-4-Tensorflow的代码样例"><a href="#1-4-Tensorflow的代码样例" class="headerlink" title="1.4 Tensorflow的代码样例"></a>1.4 Tensorflow的代码样例</h2><ol>
<li>构建数据流图的第一部分代码</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"># 创建100个numpy的 x,y 假数据点，y = x*0.1+0.3</span><br><span class="line">x_data = np.random.rand(100).astype(&quot;float32&quot;)</span><br><span class="line">y_data = x_data*0.1+0.3</span><br><span class="line"># 找出计算 y_data =W*x_data+b的w和b的值，虽然我们知道w=0.1,b=0.3,但是tensorflow会找到并计算出来</span><br><span class="line">w = tf.Variable(tf.random_uniform)</span><br></pre></td></tr></table></figure>

<h1 id="2-tensorflow概览"><a href="#2-tensorflow概览" class="headerlink" title="2 tensorflow概览"></a>2 tensorflow概览</h1><p>要使用tensorflow的话，你需要理解以下概念:</p>
<ul>
<li>图代表了计算</li>
<li>图需要在会话(Sessions)中执行</li>
<li>张量(tensor)代表数据</li>
<li>使用Variables来持有状态</li>
<li>使用<strong>feeds</strong> 和 <strong>fetches</strong>来获得任何操作的输入输出数据</li>
</ul>
<p>tensorflow的概览</p>
<ul>
<li>一个将计算转化为图的编程系统</li>
<li>图中的节点是：<ul>
<li>操作(op):执行某些计算</li>
<li>输入(input):一个或多个张量(tensorflow)</li>
<li>Tensor张量：一个有类型的多维数组</li>
</ul>
</li>
</ul>
<h1 id="3-两个计算阶段"><a href="#3-两个计算阶段" class="headerlink" title="3 两个计算阶段"></a>3 两个计算阶段</h1><h2 id="3-1-在图中计算"><a href="#3-1-在图中计算" class="headerlink" title="3.1 在图中计算"></a>3.1 在图中计算</h2><ul>
<li>图必须在Session中运行</li>
<li>会话(Session)<ul>
<li>将图操作放入到设备上，比如CPUs和GPUs</li>
<li>提供执行方法</li>
<li>返回操作产生的张量，比如python中的<strong>numpy ndarray对象</strong>，以及C和C++<strong>tensorflow::Tensor</strong>实例。</li>
</ul>
</li>
</ul>
<h2 id="3-2-图中的两个计算阶段"><a href="#3-2-图中的两个计算阶段" class="headerlink" title="3.2 图中的两个计算阶段"></a>3.2 图中的两个计算阶段</h2><ol>
<li><p>构建阶段</p>
<ul>
<li>形成图</li>
<li>创建图来代表神经网络并训练这个神经网络</li>
</ul>
</li>
<li><p>执行阶段</p>
<ul>
<li>使用会话执行途中的操作</li>
<li>重复执行图中训练操作集合</li>
</ul>
</li>
<li><p>构建图</p>
</li>
</ol>
<ul>
<li>开始那些不需要任何输入(source ops)的操作(op)，常量</li>
<li>将它们的输出传入到其他做计算的操作</li>
<li>操作构建者返回对象<ul>
<li>代表了结构化操作的输出</li>
<li>将这些输出传入其他操作构建者作为输入</li>
</ul>
</li>
</ul>
<ol start="4">
<li>默认图</li>
</ol>
<p> 将节点加入此图的操作构建者</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"># 创建一个产生1x2的矩阵的常量操作，操作被作为节点加入到默认图</span><br><span class="line"># 构建者的返回值代表了常量操作的输出</span><br><span class="line">matrix1 = tf.constant([[3,3.]])</span><br><span class="line"># 创建另外一个产生 2x1矩阵的常量操作</span><br><span class="line">matrix2 = tf.constant([[2.0],[2.]])</span><br></pre></td></tr></table></figure>
<p>   有三个节点：两个<strong>constant</strong>操作(ops)以及一个<strong>matmul</strong>操作</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个Matmul操作，将 matrix1和matrix2作为输入</span><br><span class="line"># 返回值，‘product’，代表了矩阵相乘的结果</span><br><span class="line">product = tf.matmul(matrix1,matrix2)</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>在会话Session中运行图</li>
</ol>
<ul>
<li>创建一个Session对象：应该在被关闭以释放资源</li>
<li>没有参数，session构建者运行默认图</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 运行默认图</span><br><span class="line">sess = tf.Session()</span><br><span class="line"># 要运行matmul操作，我们调用了session的‘run()’方法，传入&#x27;producr&#x27;代表了matmul操作的输出。这即回调了matmul操作的输出结果</span><br><span class="line"># 操作的输出以一个numpy的&#x27;ndarray&#x27;对象返回&#x27;result&#x27;</span><br><span class="line">result = sess.run(product)</span><br><span class="line">print result</span><br><span class="line"># ==&gt;[[12.]]</span><br><span class="line">#关闭会话</span><br><span class="line">sess.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ol start="6">
<li>Session运行图，Session.run()方法执行操作</li>
<li>一个Session块(block)<ul>
<li>在块的结尾自动关闭<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">with tf.Session() as sess:</span><br><span class="line">    result = sess.run([product])</span><br><span class="line">    print result</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>GPU的使用</li>
</ol>
<ul>
<li>将图定义转换为分布在各种计算资源，比如CPU和GPU之间的可执行操作</li>
<li>如果有GPU，tensorflow会有限使用GPU</li>
</ul>
<p>#4 交互使用</p>
<ul>
<li>在python环境中，比如Ipython,<strong>InteractiveSession</strong>类会被使用</li>
<li><strong>Tensor.eval()<strong>和</strong>Operation.run()</strong></li>
<li>这可以避免必须用一个变量来保持一个session</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 进入一个交互的Tensorflow Session</span><br><span class="line">import tensorflow as tf</span><br><span class="line">sess = tf.InteractiveSession()</span><br><span class="line"></span><br><span class="line">x = tf.Variable([1.0,2.0])</span><br><span class="line">y = tf.constant([3.0,3.0])</span><br><span class="line">#使用&#x27;x&#x27;的initializer的 run() 方法初始化</span><br><span class="line">x.initializer.run()</span><br><span class="line"></span><br><span class="line"># 添加一个操作从&#x27;x&#x27;中抽取&#x27;a&#x27;，执行并打印结果</span><br><span class="line">sub = tf.sub(x,a)</span><br><span class="line">print sub.eval()</span><br><span class="line"># ==&gt;[-2,-1.]</span><br><span class="line"></span><br><span class="line"># 关闭session</span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure>

<h1 id="5-张量-Tensors"><a href="#5-张量-Tensors" class="headerlink" title="5 张量(Tensors)"></a>5 张量(Tensors)</h1><ul>
<li>Tensor(张量)数据结构代表了所有数据</li>
<li>在计算图中只有张量在操作之间传递</li>
<li>n维数组或者列表<ul>
<li>静态类型，秩，或者 shape</li>
</ul>
</li>
</ul>
<p><strong>rank(秩)</strong></p>
<table>
<thead>
<tr>
<th>rank</th>
<th>数学实体</th>
<th>python示例</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>Scalar(大小)</td>
<td>s &#x3D;483</td>
</tr>
<tr>
<td>1</td>
<td>Vector(大小和方向)</td>
<td>v&#x3D;[1.1,2.2,3.3]</td>
</tr>
<tr>
<td>2</td>
<td>Matrix(数据表)</td>
<td>m&#x3D;[[1,2,3],[4,5,6],[7,8,9]]</td>
</tr>
<tr>
<td>3</td>
<td>3-Tensor(立方(cube)的数量)</td>
<td>t&#x3D;[[[2],[4],[6],[8]],[[10],[12]]]</td>
</tr>
<tr>
<td>n</td>
<td>n-Tensor</td>
<td>同上</td>
</tr>
</tbody></table>
<p><strong>shape</strong></p>
<p>|Rank| Shape|维数|示例|<br>|—|—|—|<br>|0|[]|0-D|一个0-D张量，一个标量|<br>|1|[D0]|1-D|一个1-D张量，shape是[5]|<br>|2|[D0,D1]|2-D|一个2-D张量，shape是[3,4]|<br>|3|[D0,D1,D2]|3-D|一个3-D张量，shape[1,4,3]|<br>|n|[D0,D1,D2,…Dn]|n-D|一个n-D张量，shape是[D0,D1,…Dn]|</p>
<p><strong>数据类型</strong></p>
<table>
<thead>
<tr>
<th>Data type</th>
<th>python类型</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>DT_FLOAT</td>
<td>tf.float32</td>
<td>32位浮点类型</td>
</tr>
<tr>
<td>DT_DOUBLE</td>
<td>tf.float64</td>
<td>64位浮点类型</td>
</tr>
<tr>
<td>DT_INT64</td>
<td>tf.int64</td>
<td>64位有符号整型</td>
</tr>
<tr>
<td>DT_INT32</td>
<td>tf.int32</td>
<td>32位有符号整型</td>
</tr>
<tr>
<td>DT_INT16</td>
<td>tf.int16</td>
<td>16位有符号整型</td>
</tr>
<tr>
<td>DT_INt8</td>
<td>tf.int8</td>
<td>8位有符号整型</td>
</tr>
<tr>
<td>DT_UINT</td>
<td>tf.unit8</td>
<td>8位无符号整型</td>
</tr>
<tr>
<td>DT_STRING</td>
<td>tf.string</td>
<td>变量长度的字节数组，Tensor每个元素是一个字节数组</td>
</tr>
<tr>
<td>DT_BOOL</td>
<td>tf.bool</td>
<td>Boolean</td>
</tr>
<tr>
<td>DT_COMPLEX64</td>
<td>tf.complex64</td>
<td>由两个32位浮点数组成的复数，实数和大小部分</td>
</tr>
<tr>
<td>DT_QINT32</td>
<td>tf.qint32</td>
<td>量化操作中32位有符号整型</td>
</tr>
<tr>
<td>DT_QINT8</td>
<td>tf.qint8</td>
<td>量化操作中8位有符号整型</td>
</tr>
<tr>
<td>DT_QUINT8</td>
<td>tf.quint8</td>
<td>量化操作中8位无符号整型</td>
</tr>
</tbody></table>
<p>#6 变量<br>变量的创建、初始化、存储和载入</p>
<ul>
<li>为了持有和更新参数，在图中保持状态可以通过调用 **run()**方法</li>
<li>内存buffer包含张量</li>
<li>必须是明确初始化并且在训练期间和训练之后存储到磁盘上的</li>
<li>类 <strong>tf.Variable</strong><ul>
<li>构造器：变量的初始化值，一个任意类型和shape的张量</li>
<li>构造之后，类型和shape都会固定</li>
<li>使用<strong>assign</strong>操作op， validate_shape &#x3D; False</li>
</ul>
</li>
</ul>
<h2 id="6-1-创建"><a href="#6-1-创建" class="headerlink" title="6.1 创建"></a>6.1 创建</h2><ul>
<li>传入一个张量作为初始值到 Variable构造方法中</li>
<li>初始值：常量constants,序列化和随机值<ul>
<li>tf.zeros(),tf.linspace(),tf.random_normal()</li>
</ul>
</li>
<li>固定shape：与操作的shape相同</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 创建两个变量</span><br><span class="line">weight = tf.Variable(tf.random_normal([784,200],stddev=0.35),name =&quot;weights&quot;)</span><br><span class="line">biases = tf.Variable(tf.zeros([200]),name =&quot;biases&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>调用 tf.Variable() 加入操作到图中</li>
</ul>
<h2 id="6-2-初始化"><a href="#6-2-初始化" class="headerlink" title="6.2 初始化"></a>6.2 初始化</h2><ul>
<li>添加一个操作并执行</li>
<li>tf.initialize_all_variables()</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 添加一个操作来初始化变量</span><br><span class="line">init_op = tf.initialize_all_variables()</span><br><span class="line"># 过后，执行model</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    #运行初始化操作</span><br><span class="line">    sess.run（init_op）</span><br></pre></td></tr></table></figure>
<h2 id="6-3-存储和恢复"><a href="#6-3-存储和恢复" class="headerlink" title="6.3 存储和恢复"></a>6.3 存储和恢复</h2><ul>
<li><strong>tf.saver</strong></li>
<li>检查点文件：Variables都存储在二进制文件中，该文件包含了一个变量名到张量值得map</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 创建一些变量</span><br><span class="line">v1 = tf.Variables(...,name =&quot;v1&quot;)</span><br><span class="line">v2 = tf.Variables(...,name=&quot;v2&quot;)</span><br><span class="line">...</span><br><span class="line">#添加一个操作来初始化变量</span><br><span class="line">init_op = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line"># 添加操作来保存和恢复所有变量</span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"># 然后，运行模型，初始化变量，做一些操作，保存变量到磁盘中</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">     sess.run(init_op)</span><br><span class="line">     # 对模型做一些操作</span><br><span class="line">    .....</span><br><span class="line">    #存储变量到磁盘中</span><br><span class="line">    save_path = saver.save(sess,&quot;/tmp/model.ckpt&quot;)</span><br><span class="line">    print (&quot;Model saved in file: %s&quot;%save_path)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>** 恢复**</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">with tf.Session() as sess:</span><br><span class="line">    # 从磁盘中恢复变量</span><br><span class="line">    saver.restore(sess,&quot;/tmp/model.ckpt&quot;)</span><br><span class="line">    print (&quot;Model restored&quot;)</span><br><span class="line">    # 做一些操作</span><br></pre></td></tr></table></figure>

<h2 id="6-4-选择哪些变量来存储和恢复"><a href="#6-4-选择哪些变量来存储和恢复" class="headerlink" title="6.4 选择哪些变量来存储和恢复"></a>6.4 选择哪些变量来存储和恢复</h2><ul>
<li><p>在 ** tf.train.Saver()**中没有参数</p>
<ul>
<li>处理图中所有变量，每个变量都会被保存在该名字之下</li>
</ul>
</li>
<li><p>存储和恢复变量的子集</p>
<ul>
<li>训练5层神经网络，想训练一个新的6层神经网络，从5层圣经网络中恢复参数</li>
</ul>
</li>
<li><p>向**tf.train.Saver()**构造方法中传入一个Python词典:keys</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 创建一些变量</span><br><span class="line">v1 = tf.Variables(...,name =&quot;v1&quot;)</span><br><span class="line">v2 = tf.Variables(...,name =&quot;v2&quot;)</span><br><span class="line"># 添加操作存储和恢复变量 v2,使用名字 &quot;my_v2&quot;</span><br><span class="line">saver = tf.train.Saver(&#123;&quot;my_v2&quot;:v2&#125;)</span><br><span class="line"># 使用saver对象</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<h2 id="6-5-简单计数器的示例代码"><a href="#6-5-简单计数器的示例代码" class="headerlink" title="6.5 简单计数器的示例代码"></a>6.5 简单计数器的示例代码</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个变量，初始化为标量0</span><br><span class="line">state = tf.Variables(0,name=&quot;Counter&quot;)</span><br><span class="line"># 创建一个操作来给&quot;state&quot;加1</span><br><span class="line">one = tf.constant(1)</span><br><span class="line">new_value = tf.add(state,one)</span><br><span class="line">update = tf.assign(state,new_value)</span><br><span class="line"></span><br><span class="line"># 在图被运行，变量必须是通过运行一个&quot;init&quot;操作被初始化。</span><br><span class="line"># 我们首先要将&quot;init&quot;操作加入到图中</span><br><span class="line">init_op = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line"># 运行图，和操作</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    #运行 &#x27;init&#x27;操作</span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    # 打印&#x27;state&#x27;的初始化值</span><br><span class="line">    print (sess.run(state))</span><br><span class="line">    # 运行更新&#x27;state&#x27;的操作，并打印&#x27;state&#x27;</span><br><span class="line">    for _ in range(3):</span><br><span class="line">        sess.run(update)</span><br><span class="line">        print (sess.run(state))</span><br><span class="line"># 输出</span><br><span class="line">#0</span><br><span class="line">#1</span><br><span class="line">#2</span><br><span class="line">#3</span><br></pre></td></tr></table></figure>

<h2 id="6-6-取数据Fetches"><a href="#6-6-取数据Fetches" class="headerlink" title="6.6 取数据Fetches"></a>6.6 取数据Fetches</h2><ul>
<li>在Session对象中调用**run()**方法来执行图，并传入张量来取回数据</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">input1 = tf.constant(3.0)</span><br><span class="line">input2 = tf.constant(2.0)</span><br><span class="line">input3 = tf.constant(5.0)</span><br><span class="line">intermed = tf.add(input2,input3)</span><br><span class="line">mul = tf.mul(input1,intermed)</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">     result = sess.run([mul,intermed])</span><br><span class="line">     print (result)</span><br><span class="line"># 输出</span><br><span class="line"># [array([21.],dtype = float32),array([7.],dtype = float32)]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="6-7-Feeds"><a href="#6-7-Feeds" class="headerlink" title="6.7 Feeds"></a>6.7 Feeds</h2><ul>
<li>直接打包一个张量到图中的任何操作</li>
<li>使用一个张量值临时替换一个操作的输出值</li>
<li>feed数据作为**run()**方法的一个参数</li>
<li>仅仅用来运行调用被传入值</li>
<li><strong>tf.placeholder()</strong></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">input1 = tf.placeholder(tf.float32)</span><br><span class="line">input2 =tf.placeholder(tf.float32)</span><br><span class="line">output = tf.mul(input1,input2)</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    print (sess.run([output],feed_dict = &#123;input1:[7.],input2:[2.]&#125;))</span><br><span class="line"></span><br><span class="line">#输出</span><br><span class="line">#[array([14.],dtype=float32)]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="7-操作"><a href="#7-操作" class="headerlink" title="7 操作"></a>7 操作</h1><table>
<thead>
<tr>
<th>类别</th>
<th>示例</th>
</tr>
</thead>
<tbody><tr>
<td>逐元素数学运算</td>
<td>Add,Sub,Mul,Div,Exp,Log,Greater,Less,Equal…</td>
</tr>
<tr>
<td>数组操作</td>
<td>Concat,Slice,Split,Constant,Rank,Shape,Shuffle..</td>
</tr>
<tr>
<td>矩阵运算</td>
<td>MatMul,MatrixInverse,MatrixDeterminant…</td>
</tr>
<tr>
<td>状态操作</td>
<td>Variable,Assign,AssignAdd…</td>
</tr>
<tr>
<td>神经元构建块</td>
<td>SoftMax,Sigmoid,ReLU,Convolution2D,MaxPool…</td>
</tr>
<tr>
<td>检查点操作</td>
<td>Save,Restore</td>
</tr>
<tr>
<td>队列和同步操作</td>
<td>Enqueue,Dequeue,MutexAcquire,MutexRelease,…</td>
</tr>
<tr>
<td>控制流操作</td>
<td>Merge,Switch,Enter,Leave,NextIteration</td>
</tr>
</tbody></table>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/09/15/2016-08-18-tensorflow-CIFAR10/" rel="prev" title="tensorflow:使用tensorflow构建简单卷积神经网络">
      <i class="fa fa-chevron-left"></i> tensorflow:使用tensorflow构建简单卷积神经网络
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/09/15/2016-03-12-spark-envirnoment/" rel="next" title="spark环境部署">
      spark环境部署 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#start-up"><span class="nav-number">1.</span> <span class="nav-text">start up</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-%E8%B0%B7%E6%AD%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B7%A5%E5%85%B7%E5%8E%86%E5%8F%B2"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 谷歌深度学习工具历史:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-%E4%BA%A7%E5%93%81%E7%89%B9%E6%80%A7"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 产品特性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-3-%E8%AE%A1%E7%AE%97%E5%9B%BE"><span class="nav-number">1.3.</span> <span class="nav-text">1.3 计算图</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-4-Tensorflow%E7%9A%84%E4%BB%A3%E7%A0%81%E6%A0%B7%E4%BE%8B"><span class="nav-number">1.4.</span> <span class="nav-text">1.4 Tensorflow的代码样例</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-tensorflow%E6%A6%82%E8%A7%88"><span class="nav-number">2.</span> <span class="nav-text">2 tensorflow概览</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-%E4%B8%A4%E4%B8%AA%E8%AE%A1%E7%AE%97%E9%98%B6%E6%AE%B5"><span class="nav-number">3.</span> <span class="nav-text">3 两个计算阶段</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-%E5%9C%A8%E5%9B%BE%E4%B8%AD%E8%AE%A1%E7%AE%97"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 在图中计算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-%E5%9B%BE%E4%B8%AD%E7%9A%84%E4%B8%A4%E4%B8%AA%E8%AE%A1%E7%AE%97%E9%98%B6%E6%AE%B5"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 图中的两个计算阶段</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-%E5%BC%A0%E9%87%8F-Tensors"><span class="nav-number">4.</span> <span class="nav-text">5 张量(Tensors)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#6-1-%E5%88%9B%E5%BB%BA"><span class="nav-number">4.1.</span> <span class="nav-text">6.1 创建</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-2-%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="nav-number">4.2.</span> <span class="nav-text">6.2 初始化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-3-%E5%AD%98%E5%82%A8%E5%92%8C%E6%81%A2%E5%A4%8D"><span class="nav-number">4.3.</span> <span class="nav-text">6.3 存储和恢复</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-4-%E9%80%89%E6%8B%A9%E5%93%AA%E4%BA%9B%E5%8F%98%E9%87%8F%E6%9D%A5%E5%AD%98%E5%82%A8%E5%92%8C%E6%81%A2%E5%A4%8D"><span class="nav-number">4.4.</span> <span class="nav-text">6.4 选择哪些变量来存储和恢复</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-5-%E7%AE%80%E5%8D%95%E8%AE%A1%E6%95%B0%E5%99%A8%E7%9A%84%E7%A4%BA%E4%BE%8B%E4%BB%A3%E7%A0%81"><span class="nav-number">4.5.</span> <span class="nav-text">6.5 简单计数器的示例代码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-6-%E5%8F%96%E6%95%B0%E6%8D%AEFetches"><span class="nav-number">4.6.</span> <span class="nav-text">6.6 取数据Fetches</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-7-Feeds"><span class="nav-number">4.7.</span> <span class="nav-text">6.7 Feeds</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7-%E6%93%8D%E4%BD%9C"><span class="nav-number">5.</span> <span class="nav-text">7 操作</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="shartoo"
      src="/images/me.jpg">
  <p class="site-author-name" itemprop="name">shartoo</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">102</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">shartoo</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v6.3.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.6.0
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/three-waves.min.js"></script>


  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>




  
<script src="/js/local-search.js"></script>













  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: 'c656cd038e01f710e260',
      clientSecret: 'e6de2ccaaf0f7069292125b8f50e27f25b95810d',
      repo: 'shartoo.github.io',
      owner: 'shartoo',
      admin: ['shartoo'],
      id: '03c28f83f07bf2648c1ef82b59f9ff5e',
        language: '',
      distractionFreeMode: 'true'
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

  <!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>
</body>
</html>
